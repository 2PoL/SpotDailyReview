import io
import pandas as pd
import streamlit as st
from pathlib import Path
import re


st.set_page_config(page_title="æ•°æ®å¤„ç†å·¥å…·", layout="wide")
st.title("ğŸ“Š æ•°æ®å¤„ç†å·¥å…·")

st.markdown("---")

# ä¾§è¾¹æ é€‰æ‹©å¤„ç†æ¨¡å¼
with st.sidebar:
    st.header("é€‰æ‹©å¤„ç†æ¨¡å¼")
    mode = st.radio(
        "",
        ["åˆå¹¶äº¤æ˜“é‡ä»·æ•°æ®", "é¢„å¤„ç†è¾¹ç•Œæ•°æ®"],
        label_visibility="collapsed"
    )

st.subheader(f"å½“å‰æ¨¡å¼: {mode}")

st.markdown("---")


def extract_online_capacity(text):
    """ä»å‡ºæ¸…æ¦‚å†µä¸­æå–åœ¨çº¿æœºç»„å®¹é‡"""
    if pd.isna(text):
        return None
    match = re.search(r'è¿è¡Œæœºç»„å®¹é‡(\d+\.?\d*)\s*MW', str(text))
    if match:
        return float(match.group(1))
    return None


def process_trading_files(uploaded_files):
    """å¤„ç†äº¤æ˜“é‡ä»·æ•°æ®æ–‡ä»¶"""
    all_data = []

    for uploaded_file in uploaded_files:
        # ä»æ–‡ä»¶åä¸­æå–å…¬å¸åç§°
        company_name = Path(uploaded_file.name).stem.split("-")[0]

        try:
            # è¯»å–Excelæ–‡ä»¶
            df = pd.read_excel(uploaded_file, sheet_name="1.äº¤æ˜“é‡ä»·æ•°æ®ä¿¡æ¯", header=1)
            df["å…¬å¸åç§°"] = company_name
            all_data.append(df)
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} æ—¶å‡ºé”™: {e}")

    if all_data:
        merged_df = pd.concat(all_data, ignore_index=True)
        return merged_df
    return None


def preprocess_boundary_files(files_dict):
    """é¢„å¤„ç†è¾¹ç•Œæ•°æ®æ–‡ä»¶"""
    result = None

    try:
        # 1. è¯»å–æ—¥å‰ç»Ÿè°ƒç³»ç»Ÿè´Ÿè·é¢„æµ‹
        if "æ—¥å‰ç»Ÿè°ƒç³»ç»Ÿè´Ÿè·é¢„æµ‹_REPORT0.xlsx" in files_dict:
            df_load = pd.read_excel(files_dict["æ—¥å‰ç»Ÿè°ƒç³»ç»Ÿè´Ÿè·é¢„æµ‹_REPORT0.xlsx"], header=0)
            df_load = df_load.iloc[1:].reset_index(drop=True)
            df_load['æ—¥æœŸ'] = pd.to_datetime(df_load.iloc[:, 1]).dt.date
            df_load['æ—¶ç‚¹'] = df_load.iloc[:, 2].astype(str)
            df_load['çœè°ƒè´Ÿè·(MW)'] = pd.to_numeric(df_load.iloc[:, 3], errors='coerce')
        else:
            return None, "ç¼ºå°‘æ–‡ä»¶: æ—¥å‰ç»Ÿè°ƒç³»ç»Ÿè´Ÿè·é¢„æµ‹_REPORT0.xlsx"

        # 2. è¯»å–æ—¥å‰æ–°èƒ½æºè´Ÿè·é¢„æµ‹
        if "æ—¥å‰æ–°èƒ½æºè´Ÿè·é¢„æµ‹_REPORT0.xlsx" in files_dict:
            df_renewable = pd.read_excel(files_dict["æ—¥å‰æ–°èƒ½æºè´Ÿè·é¢„æµ‹_REPORT0.xlsx"], header=0)
            df_renewable = df_renewable.iloc[1:].reset_index(drop=True)
            df_renewable['æ—¥æœŸ'] = pd.to_datetime(df_renewable.iloc[:, 1]).dt.date
            df_renewable['æ—¶ç‚¹'] = df_renewable.iloc[:, 2].astype(str)
            df_renewable['é£ç”µ(MW)'] = pd.to_numeric(df_renewable.iloc[:, 4], errors='coerce')
            df_renewable['å…‰ä¼(MW)'] = pd.to_numeric(df_renewable.iloc[:, 5], errors='coerce')
            df_renewable['æ–°èƒ½æºè´Ÿè·(MW)'] = pd.to_numeric(df_renewable.iloc[:, 3], errors='coerce')
        else:
            return None, "ç¼ºå°‘æ–‡ä»¶: æ—¥å‰æ–°èƒ½æºè´Ÿè·é¢„æµ‹_REPORT0.xlsx"

        # 3. è¯»å–æŠ«éœ²ä¿¡æ¯96ç‚¹æ•°æ®
        if "æŠ«éœ²ä¿¡æ¯96ç‚¹æ•°æ®_REPORT0.xlsx" in files_dict:
            df_disclosure = pd.read_excel(files_dict["æŠ«éœ²ä¿¡æ¯96ç‚¹æ•°æ®_REPORT0.xlsx"], header=0)
            df_disclosure = df_disclosure.iloc[1:].reset_index(drop=True)
            df_disclosure['æ—¥æœŸ'] = pd.to_datetime(df_disclosure.iloc[:, 1]).dt.date
            df_disclosure['æ—¶ç‚¹'] = df_disclosure.iloc[:, 2].astype(str)
            df_disclosure['éå¸‚åœºåŒ–å‡ºåŠ›(MW)'] = pd.to_numeric(df_disclosure.iloc[:, 3], errors='coerce')
        else:
            return None, "ç¼ºå°‘æ–‡ä»¶: æŠ«éœ²ä¿¡æ¯96ç‚¹æ•°æ®_REPORT0.xlsx"

        # 4. è¯»å–æ—¥å‰è”ç»œçº¿è®¡åˆ’
        if "æ—¥å‰è”ç»œçº¿è®¡åˆ’_REPORT0.xlsx" in files_dict:
            df_tie_line = pd.read_excel(files_dict["æ—¥å‰è”ç»œçº¿è®¡åˆ’_REPORT0.xlsx"], header=0)
            df_tie_line = df_tie_line.iloc[1:].reset_index(drop=True)
            df_tie_line = df_tie_line[df_tie_line.iloc[:, 1] == 'æ€»åŠ ']
            df_tie_line['æ—¥æœŸ'] = pd.to_datetime(df_tie_line.iloc[:, 2]).dt.date
            df_tie_line['æ—¶ç‚¹'] = df_tie_line.iloc[:, 3].astype(str)
            df_tie_line['è”ç»œçº¿è®¡åˆ’(MW)'] = pd.to_numeric(df_tie_line.iloc[:, 4], errors='coerce')
        else:
            return None, "ç¼ºå°‘æ–‡ä»¶: æ—¥å‰è”ç»œçº¿è®¡åˆ’_REPORT0.xlsx"

        # 5. è¯»å–æ—¥å‰å¸‚åœºå‡ºæ¸…æƒ…å†µ
        online_capacity = None
        if "æ—¥å‰å¸‚åœºå‡ºæ¸…æƒ…å†µ_TABLE.xlsx" in files_dict:
            df_clearing = pd.read_excel(files_dict["æ—¥å‰å¸‚åœºå‡ºæ¸…æƒ…å†µ_TABLE.xlsx"], header=0)
            df_clearing = df_clearing.iloc[1:].reset_index(drop=True)
            online_capacity = extract_online_capacity(df_clearing.iloc[0, 2])
        else:
            return None, "ç¼ºå°‘æ–‡ä»¶: æ—¥å‰å¸‚åœºå‡ºæ¸…æƒ…å†µ_TABLE.xlsx"

        # 6. è¯»å–æ—¥å‰æ°´ç”µè®¡åˆ’
        if "æ—¥å‰æ°´ç”µè®¡åˆ’å‘ç”µæ€»å‡ºåŠ›é¢„æµ‹_REPORT0.xlsx" in files_dict:
            df_hydro = pd.read_excel(files_dict["æ—¥å‰æ°´ç”µè®¡åˆ’å‘ç”µæ€»å‡ºåŠ›é¢„æµ‹_REPORT0.xlsx"], header=0)
            df_hydro = df_hydro.iloc[1:].reset_index(drop=True)
            df_hydro['æ—¥æœŸ'] = pd.to_datetime(df_hydro.iloc[:, 1]).dt.date
            df_hydro['æ—¶ç‚¹'] = df_hydro.iloc[:, 2].astype(str)
            df_hydro['æ°´ç”µå‡ºåŠ›(MW)'] = pd.to_numeric(df_hydro.iloc[:, 3], errors='coerce')
        else:
            return None, "ç¼ºå°‘æ–‡ä»¶: æ—¥å‰æ°´ç”µè®¡åˆ’å‘ç”µæ€»å‡ºåŠ›é¢„æµ‹_REPORT0.xlsx"

        # 7. è¯»å–96ç‚¹ç”µç½‘è¿è¡Œå®é™…å€¼
        if "96ç‚¹ç”µç½‘è¿è¡Œå®é™…å€¼_REPORT0.xlsx" in files_dict:
            df_actual = pd.read_excel(files_dict["96ç‚¹ç”µç½‘è¿è¡Œå®é™…å€¼_REPORT0.xlsx"], header=0)
            df_actual = df_actual.iloc[1:].reset_index(drop=True)
            df_actual['æ—¥æœŸ'] = pd.to_datetime(df_actual.iloc[:, 1]).dt.date
            df_actual['æ—¶ç‚¹'] = df_actual.iloc[:, 2].astype(str)
            df_actual['çœè°ƒè´Ÿè·(MW)'] = pd.to_numeric(df_actual.iloc[:, 3], errors='coerce')
            df_actual['é£ç”µ(MW)'] = pd.to_numeric(df_actual.iloc[:, 5], errors='coerce')
            df_actual['å…‰ä¼(MW)'] = pd.to_numeric(df_actual.iloc[:, 6], errors='coerce')
            df_actual['æ–°èƒ½æºè´Ÿè·(MW)'] = pd.to_numeric(df_actual.iloc[:, 7], errors='coerce')
            df_actual['æ°´ç”µå‡ºåŠ›(MW)'] = pd.to_numeric(df_actual.iloc[:, 8], errors='coerce')
            df_actual['éå¸‚åœºåŒ–å‡ºåŠ›(MW)'] = pd.to_numeric(df_actual.iloc[:, 11], errors='coerce')
        else:
            return None, "ç¼ºå°‘æ–‡ä»¶: 96ç‚¹ç”µç½‘è¿è¡Œå®é™…å€¼_REPORT0.xlsx"

        # 8. è¯»å–å®æ—¶è”ç»œçº¿è®¡åˆ’
        if "å®æ—¶è”ç»œçº¿è®¡åˆ’_REPORT0.xlsx" in files_dict:
            df_tie_line_rt = pd.read_excel(files_dict["å®æ—¶è”ç»œçº¿è®¡åˆ’_REPORT0.xlsx"], header=0)
            df_tie_line_rt = df_tie_line_rt.iloc[1:].reset_index(drop=True)
            df_tie_line_rt = df_tie_line_rt[df_tie_line_rt.iloc[:, 1] == 'æ€»åŠ ']
            df_tie_line_rt['æ—¥æœŸ'] = pd.to_datetime(df_tie_line_rt.iloc[:, 2]).dt.date
            df_tie_line_rt['æ—¶ç‚¹'] = df_tie_line_rt.iloc[:, 3].astype(str)
            df_tie_line_rt['è”ç»œçº¿è®¡åˆ’(MW)'] = pd.to_numeric(df_tie_line_rt.iloc[:, 4], errors='coerce')
        else:
            return None, "ç¼ºå°‘æ–‡ä»¶: å®æ—¶è”ç»œçº¿è®¡åˆ’_REPORT0.xlsx"

        # 9. è¯»å–ç°è´§å‡ºæ¸…ç”µä»·
        if "ç°è´§å‡ºæ¸…ç”µä»·_REPORT0.xlsx" in files_dict:
            df_price = pd.read_excel(files_dict["ç°è´§å‡ºæ¸…ç”µä»·_REPORT0.xlsx"])
            df_price = df_price[pd.to_numeric(df_price['åºå·'], errors='coerce').notna()]
            df_price['æ—¥æœŸ'] = pd.to_datetime(df_price['æ—¥æœŸ']).dt.date
            df_price['æ—¶ç‚¹'] = df_price['æ—¶ç‚¹'].astype(str)
            df_price['å®æ—¶å‡ºæ¸…ä»·æ ¼(å…ƒ/MWh)'] = pd.to_numeric(df_price['å®æ—¶å‡ºæ¸…ä»·æ ¼(å…ƒ/MWh)'], errors='coerce')
            df_price['æ—¥å‰å‡ºæ¸…ä»·æ ¼(å…ƒ/MWh)'] = pd.to_numeric(df_price['æ—¥å‰å‡ºæ¸…ä»·æ ¼(å…ƒ/MWh)'], errors='coerce')
        else:
            return None, "ç¼ºå°‘æ–‡ä»¶: ç°è´§å‡ºæ¸…ç”µä»·_REPORT0.xlsx"

        # åˆå¹¶æ‰€æœ‰æ—¥å‰æ•°æ®
        day_ahead_data = pd.merge(
            df_load[['æ—¥æœŸ', 'æ—¶ç‚¹', 'çœè°ƒè´Ÿè·(MW)']],
            df_renewable[['æ—¥æœŸ', 'æ—¶ç‚¹', 'é£ç”µ(MW)', 'å…‰ä¼(MW)', 'æ–°èƒ½æºè´Ÿè·(MW)']],
            on=['æ—¥æœŸ', 'æ—¶ç‚¹'],
            how='outer'
        )
        day_ahead_data = pd.merge(
            day_ahead_data,
            df_disclosure[['æ—¥æœŸ', 'æ—¶ç‚¹', 'éå¸‚åœºåŒ–å‡ºåŠ›(MW)']],
            on=['æ—¥æœŸ', 'æ—¶ç‚¹'],
            how='outer'
        )
        day_ahead_data = pd.merge(
            day_ahead_data,
            df_tie_line[['æ—¥æœŸ', 'æ—¶ç‚¹', 'è”ç»œçº¿è®¡åˆ’(MW)']],
            on=['æ—¥æœŸ', 'æ—¶ç‚¹'],
            how='outer'
        )
        day_ahead_data = pd.merge(
            day_ahead_data,
            df_hydro[['æ—¥æœŸ', 'æ—¶ç‚¹', 'æ°´ç”µå‡ºåŠ›(MW)']],
            on=['æ—¥æœŸ', 'æ—¶ç‚¹'],
            how='outer'
        )
        day_ahead_data = pd.merge(
            day_ahead_data,
            df_price[['æ—¥æœŸ', 'æ—¶ç‚¹', 'æ—¥å‰å‡ºæ¸…ä»·æ ¼(å…ƒ/MWh)']],
            on=['æ—¥æœŸ', 'æ—¶ç‚¹'],
            how='outer'
        )

        day_ahead_data['è¾¹ç•Œæ•°æ®ç±»å‹'] = 'æ—¥å‰'
        day_ahead_data['åœ¨çº¿æœºç»„å®¹é‡(MW)'] = online_capacity

        # åˆå¹¶æ‰€æœ‰å®æ—¶æ•°æ®
        real_time_data = df_actual[['æ—¥æœŸ', 'æ—¶ç‚¹', 'çœè°ƒè´Ÿè·(MW)', 'é£ç”µ(MW)', 'å…‰ä¼(MW)',
                                      'æ–°èƒ½æºè´Ÿè·(MW)', 'æ°´ç”µå‡ºåŠ›(MW)', 'éå¸‚åœºåŒ–å‡ºåŠ›(MW)']].copy()
        real_time_data = pd.merge(
            real_time_data,
            df_tie_line_rt[['æ—¥æœŸ', 'æ—¶ç‚¹', 'è”ç»œçº¿è®¡åˆ’(MW)']],
            on=['æ—¥æœŸ', 'æ—¶ç‚¹'],
            how='left'
        )
        real_time_data = pd.merge(
            real_time_data,
            df_price[['æ—¥æœŸ', 'æ—¶ç‚¹', 'å®æ—¶å‡ºæ¸…ä»·æ ¼(å…ƒ/MWh)']],
            on=['æ—¥æœŸ', 'æ—¶ç‚¹'],
            how='left'
        )
        real_time_data['è¾¹ç•Œæ•°æ®ç±»å‹'] = 'å®æ—¶'

        # åˆå¹¶æ—¥å‰å’Œå®æ—¶æ•°æ®
        result_df = pd.concat([day_ahead_data, real_time_data], ignore_index=True)

        # æ·»åŠ ç¼ºå¤±çš„åˆ—
        columns = ['æ—¥æœŸ', 'æ—¶ç‚¹', 'è¾¹ç•Œæ•°æ®ç±»å‹', 'ç«ä»·ç©ºé—´(MW)', 'çœè°ƒè´Ÿè·(MW)', 'é£ç”µ(MW)',
                   'å…‰ä¼(MW)', 'æ–°èƒ½æºè´Ÿè·(MW)', 'éå¸‚åœºåŒ–å‡ºåŠ›(MW)', 'æ°´ç”µå‡ºåŠ›(MW)',
                   'è”ç»œçº¿è®¡åˆ’(MW)', 'åœ¨çº¿æœºç»„å®¹é‡(MW)', 'æ—¥å‰å‡ºæ¸…ä»·æ ¼(å…ƒ/MWh)',
                   'å®æ—¶å‡ºæ¸…ä»·æ ¼(å…ƒ/MWh)', 'è´Ÿè·ç‡(%)']

        for col in columns:
            if col not in result_df.columns:
                result_df[col] = None

        result_df = result_df[columns]

        # æ’åº
        result_df['æ—¶ç‚¹_æ’åº'] = pd.to_datetime(result_df['æ—¶ç‚¹'], format='%H:%M', errors='coerce')
        result_df['è¾¹ç•Œæ•°æ®ç±»å‹_æ’åº'] = result_df['è¾¹ç•Œæ•°æ®ç±»å‹'].map({'æ—¥å‰': 0, 'å®æ—¶': 1})
        result_df = result_df.sort_values(['è¾¹ç•Œæ•°æ®ç±»å‹_æ’åº', 'æ—¥æœŸ', 'æ—¶ç‚¹_æ’åº']).reset_index(drop=True)
        result_df = result_df.drop(columns=['æ—¶ç‚¹_æ’åº', 'è¾¹ç•Œæ•°æ®ç±»å‹_æ’åº'])

        return result_df, None

    except Exception as e:
        return None, f"å¤„ç†å‡ºé”™: {str(e)}"


def to_excel(df):
    """å°†DataFrameè½¬æ¢ä¸ºExcelæ–‡ä»¶å­—èŠ‚æµ"""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name="åˆå¹¶æ•°æ®")
    return output


# ==================== æ¨¡å¼1: åˆå¹¶äº¤æ˜“é‡ä»·æ•°æ® ====================
if mode == "åˆå¹¶äº¤æ˜“é‡ä»·æ•°æ®":
    st.markdown("### ğŸ“¤ ä¸Šä¼ äº¤æ˜“é‡ä»·æ•°æ®æ–‡ä»¶")
    st.info("è¯·ä¸Šä¼ åŒ…å« '1.äº¤æ˜“é‡ä»·æ•°æ®ä¿¡æ¯' sheet çš„Excelæ–‡ä»¶ï¼Œæ–‡ä»¶åæ ¼å¼å¦‚ï¼šå…¬å¸å-ç”µåŠ›è¥é”€ä¿¡æ¯ç»Ÿè®¡æ—¥æœŸ.xlsx")

    uploaded_files = st.file_uploader(
        "é€‰æ‹©Excelæ–‡ä»¶",
        type=['xlsx'],
        accept_multiple_files=True,
        help="æ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ "
    )

    if uploaded_files:
        st.markdown(f"âœ… å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼š")
        for file in uploaded_files:
            st.write(f"  - {file.name}")

        if st.button("ğŸ”„ å¼€å§‹å¤„ç†", type="primary"):
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
                result_df = process_trading_files(uploaded_files)

                if result_df is not None:
                    st.success("âœ… å¤„ç†å®Œæˆï¼")
                    st.session_state['trading_result'] = result_df
                    st.session_state['trading_filename'] = "åˆå¹¶äº¤æ˜“é‡ä»·æ•°æ®.xlsx"

                    # æ˜¾ç¤ºç»“æœç»Ÿè®¡
                    st.markdown("### ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡")
                    col1, col2, col3 = st.columns(3)
                    col1.metric("æ€»è¡Œæ•°", len(result_df))
                    col2.metric("å…¬å¸æ•°é‡", result_df["å…¬å¸åç§°"].nunique())
                    col3.metric("åˆ—æ•°", len(result_df.columns))

                    # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                    st.markdown("### ğŸ‘€ æ•°æ®é¢„è§ˆ")
                    st.dataframe(result_df.head(20), use_container_width=True)
                else:
                    st.error("âŒ å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")

    # ä¸‹è½½æŒ‰é’®ï¼ˆå¦‚æœæœ‰ç»“æœï¼‰
    if 'trading_result' in st.session_state:
        st.markdown("---")
        st.markdown("### ğŸ“¥ ä¸‹è½½æ•°æ®")
        excel_data = to_excel(st.session_state['trading_result'])
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½åˆå¹¶åçš„Excelæ–‡ä»¶",
            data=excel_data.getvalue(),
            file_name=st.session_state['trading_filename'],
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )


# ==================== æ¨¡å¼2: é¢„å¤„ç†è¾¹ç•Œæ•°æ® ====================
else:
    st.markdown("### ğŸ“¤ ä¸Šä¼ è¾¹ç•Œæ•°æ®æ–‡ä»¶")
    st.warning("âš ï¸ è¯·ä¸Šä¼ ä»¥ä¸‹9ä¸ªå¿…éœ€çš„Excelæ–‡ä»¶ï¼š")
    st.markdown("""
    1. æ—¥å‰ç»Ÿè°ƒç³»ç»Ÿè´Ÿè·é¢„æµ‹_REPORT0.xlsx
    2. æ—¥å‰æ–°èƒ½æºè´Ÿè·é¢„æµ‹_REPORT0.xlsx
    3. æŠ«éœ²ä¿¡æ¯96ç‚¹æ•°æ®_REPORT0.xlsx
    4. æ—¥å‰è”ç»œçº¿è®¡åˆ’_REPORT0.xlsx
    5. æ—¥å‰å¸‚åœºå‡ºæ¸…æƒ…å†µ_TABLE.xlsx
    6. æ—¥å‰æ°´ç”µè®¡åˆ’å‘ç”µæ€»å‡ºåŠ›é¢„æµ‹_REPORT0.xlsx
    7. 96ç‚¹ç”µç½‘è¿è¡Œå®é™…å€¼_REPORT0.xlsx
    8. å®æ—¶è”ç»œçº¿è®¡åˆ’_REPORT0.xlsx
    9. ç°è´§å‡ºæ¸…ç”µä»·_REPORT0.xlsx
    """)

    uploaded_files = st.file_uploader(
        "é€‰æ‹©Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
        type=['xlsx'],
        accept_multiple_files=True,
        help="è¯·ä¸Šä¼ ä¸Šè¿°9ä¸ªå¿…éœ€æ–‡ä»¶"
    )

    if uploaded_files:
        st.markdown(f"âœ… å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼š")
        # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
        required_files = {
            "æ—¥å‰ç»Ÿè°ƒç³»ç»Ÿè´Ÿè·é¢„æµ‹_REPORT0.xlsx": False,
            "æ—¥å‰æ–°èƒ½æºè´Ÿè·é¢„æµ‹_REPORT0.xlsx": False,
            "æŠ«éœ²ä¿¡æ¯96ç‚¹æ•°æ®_REPORT0.xlsx": False,
            "æ—¥å‰è”ç»œçº¿è®¡åˆ’_REPORT0.xlsx": False,
            "æ—¥å‰å¸‚åœºå‡ºæ¸…æƒ…å†µ_TABLE.xlsx": False,
            "æ—¥å‰æ°´ç”µè®¡åˆ’å‘ç”µæ€»å‡ºåŠ›é¢„æµ‹_REPORT0.xlsx": False,
            "96ç‚¹ç”µç½‘è¿è¡Œå®é™…å€¼_REPORT0.xlsx": False,
            "å®æ—¶è”ç»œçº¿è®¡åˆ’_REPORT0.xlsx": False,
            "ç°è´§å‡ºæ¸…ç”µä»·_REPORT0.xlsx": False
        }

        files_dict = {}
        for file in uploaded_files:
            files_dict[file.name] = file
            if file.name in required_files:
                required_files[file.name] = True
            st.write(f"  - {file.name}")

        missing_files = [name for name, found in required_files.items() if not found]
        if missing_files:
            st.warning(f"âš ï¸ è¿˜ç¼ºå°‘ {len(missing_files)} ä¸ªå¿…éœ€æ–‡ä»¶ï¼š")
            for name in missing_files:
                st.write(f"  - {name}")
        else:
            st.success("âœ… æ‰€æœ‰å¿…éœ€æ–‡ä»¶å·²ä¸Šä¼ ï¼")

        if st.button("ğŸ”„ å¼€å§‹å¤„ç†", type="primary", disabled=len(missing_files) > 0):
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
                result_df, error = preprocess_boundary_files(files_dict)

                if result_df is not None:
                    st.success("âœ… å¤„ç†å®Œæˆï¼")
                    st.session_state['boundary_result'] = result_df
                    st.session_state['boundary_filename'] = "é¢„å¤„ç†ç»“æœ_æ–°ç‰ˆ.xlsx"

                    # æ˜¾ç¤ºç»“æœç»Ÿè®¡
                    st.markdown("### ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡")
                    col1, col2, col3 = st.columns(3)
                    col1.metric("æ€»è¡Œæ•°", len(result_df))
                    col2.metric("æ—¥å‰æ•°æ®è¡Œæ•°", len(result_df[result_df['è¾¹ç•Œæ•°æ®ç±»å‹'] == 'æ—¥å‰']))
                    col3.metric("å®æ—¶æ•°æ®è¡Œæ•°", len(result_df[result_df['è¾¹ç•Œæ•°æ®ç±»å‹'] == 'å®æ—¶']))

                    # æ˜¾ç¤ºåœ¨çº¿æœºç»„å®¹é‡
                    if 'åœ¨çº¿æœºç»„å®¹é‡(MW)' in result_df.columns:
                        online_cap = result_df['åœ¨çº¿æœºç»„å®¹é‡(MW)'].dropna().iloc[0] if not result_df['åœ¨çº¿æœºç»„å®¹é‡(MW)'].dropna().empty else "æœªæ‰¾åˆ°"
                        st.info(f"ğŸ’¡ æå–åˆ°åœ¨çº¿æœºç»„å®¹é‡: {online_cap} MW")

                    # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                    st.markdown("### ğŸ‘€ æ•°æ®é¢„è§ˆ")
                    st.dataframe(result_df.head(30), use_container_width=True)
                else:
                    st.error(f"âŒ {error}")

    # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®ï¼ˆå¦‚æœæœ‰ç»“æœï¼‰
    if 'boundary_result' in st.session_state:
        st.markdown("---")
        st.markdown("### ğŸ“¥ ä¸‹è½½é¢„å¤„ç†ç»“æœ")
        excel_data = to_excel(st.session_state['boundary_result'])
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½é¢„å¤„ç†åçš„Excelæ–‡ä»¶",
            data=excel_data.getvalue(),
            file_name=st.session_state['boundary_filename'],
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

st.markdown("---")
st.caption("ğŸ’¡ æç¤ºï¼šä¸Šä¼ çš„æ–‡ä»¶ä¸ä¼šè¢«æ°¸ä¹…ä¿å­˜ï¼Œä»…ç”¨äºå½“å‰ä¼šè¯")
